## 线程安全的 Singleton 实现
[Singleton:https://github.com/Light-City/CPlusPlusThings/tree/master/design_pattern/singleton](annotation/Singleton.md)

DCL 乱序性
为此，作者想在实践中实现 pthread_once
```cpp
template<typename T>
class Singleton :boost::noncopyable {
private:
    static T& instance()
    {
        pthread_once(&ponce_, &Signleton::init);
        return *value_;
    }
private:
    Singleton();
    ~Singleton();
 
    static void init()
    {
        value_ = new T();
    }
private:
    static pthread_once_t ponce_;
    static T* value_;
};
 
//必须在头文件中定义static变量
template<typename T>
pthread_once_t Singleton<T>::ponce_ = PTHREAD_ONCE_INIT;
 
template<typename T>
T* Singleton<T>::value_ = NULL;
```
上面这个Singleton没有任何花哨的技巧：
它用pthread_once_t来保证 lazy-initialization的线程安全
线程安全性由Pthreads库保证，如果系统的Pthreads库有bug，那就认命吧，多线程程序反正也不可能正确执行了
使用方法也很简单：
`Foo& foo = Singleton<Foo>::instance();`
这个Singleton没有考虑对象的销毁：
在长时间运行的服务器程序里，这不是一个问题，反正进程也不打算正常退出（参阅后面的“分布式系统工程实践之能随时重启进行作为系统的重要目标”）
在短期运行的程序中，程序退出的时候自然就释放所有资源了（前提是程序里不使用不能由操作系统自动关闭的资源，比如跨进程的mutex）
在实际的muduo::Singleton class中，通过atexit(3)提供了销毁功能，聊胜于无罢了
另外，这个Singleton只能调用默认构造函数，如果用户想要指定T的构造方式，我们可以用模板特化技术来提供 一个定制点，这需要引入另一层间接

## sleep不是同步原语
一些说明：
我认为sleep()/usleep()/nanosleep()只能出现在测试代码中，比如写单元测试的时候（备注：设计时间的单元测试不那么好写，短的如一两秒可以用sleep()；长的如一小时、一天，则得想其他办法，比如把算法提取出来并把时间注入进去）
或者用于有意延长临界区，加速复现死锁的情况，就像“前文介绍的死锁”示范的那样
sleep不具备memory barrier语义，它不能保证内存的可见性（参阅后面“C++多线程系统编程精要”的文章最开始的例子）
生产代码中线程的等待可分为两种：
1. 一种是等待资源可用（要么等在select/poll/epoll_wait上，要么等在条件变量上，我们自己设计的“等待BlockingQueue/CountDownLatch”也可归入此处）
2. 一种是等着进入临界区（等在mutex上）以便读写共享数据。这一种等待通常极短，否则程序性能和伸缩性就会有问题
在程序的正常执行中：
如果需要等待一段已知的时间，应该往event loop里注册一个timer，然后在timer的回调函数里接着干活，因为线程是个珍贵的共享资源，不能轻易浪费（阻塞也是浪费）
如果等待某个事件发生，那么应该采用条件变量或IO事件回调，不能用sleep来轮询
不要使用下面这种业余做法：
```cpp
while (true)
{
    if (!dataAvailable)
        sleep(some_time);
    else
        consumeDta();
}
```
总结：
1. 如果多线程的安全性和效率要靠代码主动调用sleep来保证，这显然是设计出了问题
2. 等待某个事件发生，正确的做法是用select()等价物或Condition，抑或（更理想地）高层同步工具
3. 在用户态做轮询 （polling）是低效的


## 借助 shared_ptr 实现 copy-on-write
本节解决前面文章的几个未决问题：
post()和traverse()死锁
把Request::print()移出Inventory::printAll()临界区
解决Request对象析构的race condition

解决办法都基于同一个思路，那就是用shared_ptr来管理共享数据。原理如下：
* shared_ptr是引用计数型智能指针，如果当前只有一个观察者，那么引用计数的值为1（实际代码中判断shared_ptr::unique()是否为true）
* 对于write端，如果发现引用计数为1，这时可以安全地修改共享对 象，不必担心有人正在读它
* 对于read端，在读之前把引用计数加1，读完之后减1，这样保证在读的期间其引用计数大于1，可以阻止并发写
* 比较难的是，对于write端，如果发现引用计数大于1，该如何处理？sleep()一小段时间肯定是错的
  
1. post()和traverse()死锁
   ```cpp
   MutexLock mutex;
   std::vector<Foo> foos;
    
   void post(const Foo& f)
   {
       MutexLockGuard lock(&mutex);
       foos.push_back(f);
   }
    
   void traverse()
   {
       MutexLockGuard lock(&mutex);
       for (std::vector<Foo>::const_iterator it = foos.begin();
               it != foos.end(); ++it)
       {
           it->doit(); //doit()中调用post（）则会导致死锁。
       }
   }
   ```

   解决：
   ```cpp
   //在read端，用一个栈上局部FooListPtr变量当做“观察者”，它使得g_foos的引用计数增加（6）。traverse（）函数的临界区是L4~L8，临界区内只读了一次共享变量g_foos（这里多线程并发读写shared_ptr，因此必须用mutex保护），比原来的写法大为缩短。而且多个线程同时调用traverse（）也不会相互阻塞。
   typedef std::vector<Foo> FooList;
   typedef std::shared_ptr<FooList> FooListPtr;
   MutexLock mutex;
   FooList g_foos;
   //read 端
   void traverse()
   {
       FooListPtr foos;
       {
           MutexLockGuard lock(mutex);
           foos = g_foos; //使得g_foos的引用计数增加
           assert(!g_foos.unique());
       }
    
       //assert(!foos.unique())这个断言不成立
       for (std::vector<Foo>::const_iterator it = foos->begin(); 
           it != foos->end(); ++it)
       {
           it->doit();
       }
   }

   //write 端 如果g_foos.unique()为false，说明别的线程正在读取FooList，我们不能原地修改，而是复制一份，在副本上修改；如果g_foos.unique()为true，说明没有任何读写端对g_foos操作，因此可以放心地在原地修改FooList。这样就避免了死锁

   void post(const Foo& f)
   {
       printf("post\n");
       MutexLockGuard lock(mutex);
    
       //g_foos不唯一，那么在副本上进行修改
       if (!g_foos.unique())
       {
           //p.reset（new AglSeq（））:对应于指向原始对象的指针的参考计数减1，如果将参考计数减为0，则释放该对象的内存；否则，返回0。对应于指针并指向新对象的引用计数增加一；
           //p.reset（）对应于指向原始对象的指针的参考计数减1，如果将参考计数减为0，则释放该对象的内存；否则，返回0。
           g_foos.reset(new FooList(*g_foos));//直接让g_foos 指向新拷贝的复制区.
           printf("copy the whole list\n");
       }
    
       assert(g_foos.unique());
       g_foos->push_back(f);
   }
   ```

   错误写法：
   ```cpp
   //错误一：直接修改g_foos所指的FooList
   void post(const Foo& f)
   {
       MutexLockGuard lock(mutex);
       g_foos->push_back(f);
   }
    
   //错误二：试图缩小临界区，把copying移除临界区
   void post(const Foo& f)
   {
       FooListPtr newFoos(new FooList(*g_foos));
       newFoos->push_back(f);
       MutexLockGuard lock(mutex);
       g_foos = newFoos; //或者g_foos.swap(newFoos);
   }
    
   //错误三：把临界区拆成两个小的，把copying放到临界区之外
   void post(const Foo& f)
   {
       FooListPtr oldFoos;
       {
           MutexLockGuard lock(mutex);
           oldFoos = g_foos;
       }
    
       FooListPtr newFoos(new FooList(*g_foos));
       newFoos->push_back(f);
       MutexLockGuard lock(mutex);
       g_foos = newFoos; //或者g_foos.swap(newFoos);
   }
   ```
2. 把Request::print()移出Inventory::printAll()临界区
   做法1：把requests_复制一份，在临界区之外遍历这个副本。但是开销较大
   ```cpp
   class Inventory
   {
   public:
       //其余同前面文章
       void printAll()const
       {
           std::set<Request*> requests
           {
               muduo::MutexLockGuard lock(mutex_);
               requests = requests_;
           }
           //遍历局部变量requests，调用Request::print()
       }
   private:
       mutable muduo::MutexLock mutex_;
       std::set<Request*> requests_;
   };
   ```
   做法2：做法②（copy-on-wirte）
   为了避免做法①所带来的的开销，如果遍历期间没有其他人修改requests_，那么我们可以减小开销
   例如：
   用shared_ptr管理std::set，在遍历的时候先增加引用计数，阻止并发修改
   当然Inventory::add()和Inventory::remove()也要相应修改，原理与上面的post()和reaverse()原理相似。可以参阅：recipes/thread/test/Request-Inventory.cc
3. 用普通mutex替换读写锁的一个例子
   > 场景：
   > 一个多线程的C++程序，24h x 5.5d运行
   > 有几个工作线程ThreadWorker{0, 1, 2, 3}，处理客户发过来的交易请求;另外有一个背景线程ThreadBackground，不定期更新程序内部的参考数据
   > 这些线程都跟一个hash表打交道，工作线程只读，背景线程读写，必然要用到一 些同步机制，防止数据损坏。这里的示例代码用std::map代替hash表， 意思是一样的：
   > map的key是用户名，value是一个vector（里面存的是不同stock的最小交易间隔，vector已经排序好，可以用二分查找）
   > `typedef std::map<std::string, std::vector<std::pair<std::string, int>>> Map;`
   > 我们的系统要求工作线程的延迟尽可能小，可以容忍背景线程的延迟略大。一天之内，背景线程对数据更新的次数屈指可数，最多一小时一次，更新的数据来自于网络，所以对更新的及时性不敏感。Map的数据量也不大，大约一千多条数据

   解决办法：
   1. 最简单的同步办法是用读写锁：工作线程加读锁，背景线程加写锁。
      但是读写锁的开销比普通mutex要大，而且是写锁优先，会阻塞后面的读锁。如果工作线程能用最普通的非重入mutex实现同步，就不必用读写锁，这能降低工作线程延迟。
   2. 我们借助shared_ptr做到了这一点：
      ```cpp
      class CustomerData :boost::noncopyable 
      {
      public:
          CustomerData() :data_(new Map) {}
       
          int query(const std::string& customer, const std::string& stock)const;
      private:
          typedef std::pair<std::string, int> Entry;
          typedef std::vector<Entry> EntryList;
          typedef std::map<std::string, EntryList> Map;
          typedef std::tr1::shared_ptr<Map> MapPtr;
       
          void update(const std::string& customer, const EntryList& entries);
       
          //用lower_bound在entries里找stock
          static int findEntry(const EntryList& entries, const std::string& stock);
       
          MapPtr getData()const
          {
              MutexLockGuard lock(mutex_);
              return data_;
          }
       
          mutable MutexLock mutex_;
          MapPtr data_;
      };

      //read端: CustomerData::query()就用前面说的引用计数加1的办法，用局部MapPtr data变量来持有Map，防止并发修改：
      int CustomerData::query(const std::string& customer, const std::string& stock)const
      {
          MapPtr data = getData();//使shared_ptr引用计数加1
          //data一旦拿到，就不再需要锁了，getData()中已经加锁
          //取数据的时候只有getData()内部加锁，多线程并发读的性能很好
       
          //因为只有getData()进行了加锁，所以getData()函数执行完之后锁自动释放
          //因此下面可能会读取到旧的数据，但这不是问题(见下面注意事项)
          Map::const_iterator entries = data->find(customer);
          if (entries != data->end())
              return findEntry(entries->second, stock);
          else
              return -1;
      }
      //write 端:）关键看CustomerData::update()怎么写，既然要更新数据，那肯定得加锁：如果这时候其他线程正在读，那么不能在原来的数据上修改，得创建一个副本，在副本上修改，修改完了再替换如果没有用户在读， 那么就能直接修改，节约一次Map拷贝
      void CustomerData::update(const std::string& customer, const EntryList& entries)
      {
          MutexLockGuard lock(mutex_); //update 必须全程持锁
          
          if (!data_.unique())
          {
              MapPtr newData(new Map(*data_));
              //可以在这里打印日志，然后统计日志来判断worst case发生的次数
              data_.swap(newData);//交换指针，data_指向复制区，在复制区更改
          }
       
          
          assert(data_.unique());
          (*data_)[customer] = entries;
      }

      ```

      其中用了shared_ptr::unique()来判断是不是有人在读，如果有人在读，那么我们不能直接修改，因为query()并没有全程加锁，只在getData()内部有锁。shared_ptr::swap()把data_替换为新副本，而且我们还在锁里，不会有别的线程来读，可以放心地更。如果别的reader线程已经刚刚通过getData()拿到了MapPtr，它会读到稍旧的数据。这不是问题，因为数据更新来自网络，如果网络稍有延迟，反正reader线程也会读到旧的数据。
      如果每次都更新全部数据，而且始终是在同一个线程更新数据，临界区还可以进一步缩小：
      ```cpp
      MapPtr parseData(const std::string& message);
            
      void CustomerData::update(const std::string& message)
      {
      //解析数据，在临界区之外
      MapPtr newData = parseData(message);

      if (newData)
      {
      MutexLockGuard lock(mutex_);
      data_.swap(newData); //不要用data_ = newData
      }
      //旧数据的析构也在临界区之外，进一步缩短了临界区
       
      }

      ```
      据我们测试，大多数情况下更新都是在原来数据上进行的，拷贝的比例还不到1％，很高效。更准确地说，这不是copy-on-write，而是copy-on-other-reading。
      我们将来可能会采用无锁数据结构，不过目前这个实现已经非常好，可以满足我们的要求。

本文介绍的做法与read-copy-updaye颇有相似之处，但理解起来容器很多。